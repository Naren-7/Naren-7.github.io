# **Portfolio**

## **Data Sience**
### **Reporte Copa KC Noviembre 2022**

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/Naren-7/report-kc-nov-22)
[![](https://img.shields.io/badge/DeepNote-View%20Profile-blue?logo=deepnote)](https://deepnote.com/workspace/naren-dfe2-c559a112-f9f8-49fd-9912-4a5d1e80c3e1/project/Noviembre-2022-Yu-go-oh-ebe977c2-d571-4d01-899e-ea2924946f78/notebook/report-kc-nov-22%2FReporte_KC_Noviembre_2022-f6dd942e3de74e4fb19ddddfad1594cf)


<div style="text-align: justify">

[Yu-Gi-Oh! Duel Links](https://www.konami.com/yugioh/duel_links/en/) es un videojuego de cartas coleccionables digital con mecánica free-to-play con microtransacciones desarrollado por Konami para Windows descargable con Steam, iOS y Android. Primero se lanza en Japón el 17 de noviembre de 2016 y se libera a nivel mundial el 11 de enero de 2017. En el lore del juego, Seto Kaiba a través de su corporación crea una realidad virtual llamada "Duel World" para reunir a los mejores duelistas para que puedan competir donde a lo largo del tiempo acompañan los personajes de las diferentes sagas y spin-offs.

Por medio de ello realiza cada cierto tiempo la copa Kaiba Corporation para demostrar quien es el mejor duelista del planeta.

Es un sistema de ranking que consta de 2 fases, en resumen la fase 1 recompensa gemas que son la moneda del juego y en la fase 2 da premio al 1er lugar para clasificar al mundial de yugioh pero no recompensa gemas. Por lo que la comunidad normalmente prioriza la fase 1 que te da recursos para la cuenta.
</div>


<center><img src="https://camo.githubusercontent.com/b4b2e0e7e75edbf630418a26e4bbd45bebe8cfe640371545ecdee4ea488aba57/68747470733a2f2f73332e6475656c6c696e6b736d6574612e636f6d2f696d672f636f6e74656e742f746f75726e616d656e74732f6b632d6375702f646c6d2d6b632d696e74726f2e77656270"/></center>






<!-- 
---
### **Predicion de datos**

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/Naren-7/Naren-7.github.io)
[![](https://img.shields.io/badge/DeepNote-View%20Profile-blue?logo=deepnote)](https://deepnote.com/workspace/naren-dfe2-c559a112-f9f8-49fd-9912-4a5d1e80c3e1)


<div style="text-align: justify">
The release of Google's BERT is described as the beginning of a new era in NLP. In this notebook I'll use the HuggingFace's transformers library to fine-tune pretrained BERT model for a classification task. Then I will compare BERT's performance with a baseline model, in which I use a TF-IDF vectorizer and a Naive Bayes classifier. The transformers library helps us quickly and efficiently fine-tune the state-of-the-art BERT model and yield an accuracy rate 10% higher than the baseline model.
</div>


<center><img src="images/dummy_thumbnail.jpg?raw=true"/></center>

---

### Predict Breast Cancer with RF, PCA and SVM using Python

[![Open Notebook](https://img.shields.io/badge/Jupyter-Open_Notebook-blue?logo=Jupyter)](projects/breast-cancer.html)
[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/chriskhanhtran/predict-breast-cancer-with-rf-pca-svm/blob/master/breast-cancer.ipynb)

<div style="text-align: justify">In this project I am going to perform comprehensive EDA on the breast cancer dataset, then transform the data using Principal Components Analysis (PCA) and use Support Vector Machine (SVM) model to predict whether a patient has breast cancer.</div>

<br>
<center><img src="images/dummy_thumbnail.jpg?raw=true"/></center>
<br>


---


<!-- Una nueva categoria de proyectos -->
<!-- 
## **Otra categoria**


### **Predicion de datos**

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/Naren-7/Naren-7.github.io)
[![](https://img.shields.io/badge/DeepNote-View%20Profile-blue?logo=deepnote)](https://deepnote.com/workspace/naren-dfe2-c559a112-f9f8-49fd-9912-4a5d1e80c3e1)


<div style="text-align: justify">
The release of Google's BERT is described as the beginning of a new era in NLP. In this notebook I'll use the HuggingFace's transformers library to fine-tune pretrained BERT model for a classification task. Then I will compare BERT's performance with a baseline model, in which I use a TF-IDF vectorizer and a Naive Bayes classifier. The transformers library helps us quickly and efficiently fine-tune the state-of-the-art BERT model and yield an accuracy rate 10% higher than the baseline model.
</div>





<br>
<center><img src="images/dummy_thumbnail.jpg?raw=true"/></center>
<br> --> 



